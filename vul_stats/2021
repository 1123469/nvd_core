11232
[('CWE-79', 2662), ('CWE-787', 1518), ('NVD-CWE-Other', 838), ('CWE-125', 769), ('CWE-89', 750), ('CWE-416', 629), ('CWE-20', 610), ('CWE-22', 528), ('CWE-78', 469), ('CWE-476', 441), ('CWE-120', 383), ('CWE-352', 373), ('CWE-269', 337), ('CWE-863', 319), ('CWE-434', 304), ('CWE-287', 302), ('CWE-77', 298), ('CWE-862', 280), ('CWE-119', 248), ('CWE-502', 230), ('CWE-190', 228), ('CWE-200', 204), ('CWE-276', 181), ('CWE-668', 179), ('CWE-918', 164), ('CWE-798', 160), ('CWE-400', 157), ('CWE-732', 142), ('CWE-74', 139), ('CWE-306', 132), ('CWE-601', 131), ('CWE-94', 123), ('CWE-522', 120), ('CWE-611', 120), ('CWE-295', 120), ('CWE-362', 118), ('CWE-427', 113), ('CWE-770', 109), ('CWE-401', 106), ('CWE-617', 103), ('CWE-59', 102), ('CWE-312', 102), ('CWE-203', 100), ('CWE-532', 94), ('CWE-319', 87), ('CWE-415', 83), ('CWE-369', 80), ('CWE-639', 79), ('CWE-835', 78), ('CWE-755', 78), ('CWE-843', 76), ('CWE-327', 76), ('CWE-1021', 73), ('CWE-1321', 72), ('CWE-121', 71), ('CWE-347', 69), ('CWE-908', 67), ('CWE-209', 67), ('CWE-754', 57), ('CWE-444', 49), ('CWE-613', 49), ('CWE-122', 48), ('CWE-345', 46), ('CWE-307', 46), ('CWE-326', 46), ('CWE-552', 45), ('CWE-330', 42), ('CWE-665', 41), ('CWE-824', 39), ('CWE-610', 38), ('CWE-346', 37), ('CWE-281', 36), ('CWE-116', 35), ('CWE-788', 35), ('CWE-367', 34), ('CWE-290', 31), ('CWE-191', 30), ('CWE-1236', 29), ('CWE-252', 29), ('CWE-88', 27), ('CWE-428', 27), ('CWE-697', 25), ('CWE-425', 25), ('CWE-674', 25), ('CWE-829', 24), ('CWE-129', 24), ('CWE-667', 24), ('CWE-640', 23), ('CWE-131', 23), ('CWE-404', 23), ('CWE-922', 22), ('CWE-384', 21), ('CWE-1188', 21), ('CWE-682', 21), ('CWE-521', 21), ('CWE-681', 20), ('CWE-772', 19), ('CWE-311', 19), ('CWE-426', 18), ('CWE-909', 18), ('CWE-91', 16), ('CWE-294', 16), ('CWE-134', 14), ('CWE-459', 14), ('CWE-916', 14), ('CWE-834', 14), ('CWE-704', 13), ('CWE-338', 12), ('CWE-354', 11), ('CWE-913', 11), ('CWE-763', 11), ('CWE-670', 11), ('CWE-669', 10), ('CWE-331', 10), ('CWE-436', 10), ('CWE-212', 10), ('CWE-494', 10), ('CWE-379', 9), ('CWE-1333', 9), ('CWE-706', 9), ('CWE-178', 8), ('CWE-776', 8), ('CWE-193', 8), ('CWE-693', 7), ('CWE-472', 7), ('CWE-799', 6), ('CWE-565', 6), ('CWE-457', 6), ('CWE-170', 6), ('CWE-707', 6), ('CWE-680', 6), ('CWE-662', 6), ('CWE-123', 6), ('CWE-23', 5), ('CWE-73', 5), ('CWE-789', 5), ('CWE-822', 4), ('CWE-184', 4), ('CWE-335', 4), ('CWE-924', 4), ('CWE-548', 4), ('CWE-377', 4), ('CWE-273', 4), ('CWE-321', 4), ('CWE-1284', 3), ('CWE-259', 3), ('CWE-266', 3), ('CWE-201', 3), ('CWE-471', 3), ('CWE-917', 3), ('CWE-489', 3), ('CWE-288', 3), ('CWE-406', 3), ('CWE-250', 3), ('CWE-497', 3), ('CWE-284', 3), ('CWE-538', 2), ('CWE-807', 2), ('CWE-126', 2), ('CWE-359', 2), ('CWE-93', 2), ('CWE-708', 2), ('CWE-1241', 2), ('CWE-61', 2), ('CWE-644', 2), ('CWE-80', 2), ('CWE-657', 2), ('CWE-353', 2), ('CWE-912', 2), ('CWE-202', 2), ('CWE-470', 2), ('CWE-240', 2), ('CWE-277', 2), ('CWE-710', 1), ('CWE-590', 1), ('CWE-1278', 1), ('CWE-805', 1), ('CWE-257', 1), ('CWE-99', 1), ('CWE-228', 1), ('CWE-332', 1), ('CWE-757', 1), ('CWE-1286', 1), ('CWE-115', 1), ('CWE-540', 1), ('CWE-778', 1), ('CWE-1287', 1), ('CWE-1004', 1), ('CWE-304', 1), ('CWE-242', 1), ('CWE-36', 1), ('CWE-214', 1), ('CWE-456', 1), ('CWE-525', 1), ('CWE-15', 1), ('CWE-302', 1), ('CWE-248', 1), ('CWE-838', 1), ('CWE-124', 1), ('CWE-378', 1), ('CWE-315', 1), ('CWE-527', 1), ('CWE-90', 1), ('CWE-620', 1), ('CWE-1076', 1), ('CWE-285', 1), ('CWE-672', 1), ('CWE-297', 1), ('CWE-95', 1), ('CWE-1329', 1), ('CWE-64', 1), ('CWE-267', 1), ('CWE-350', 1), ('CWE-597', 1), ('CWE-598', 1), ('CWE-75', 1), ('CWE-1336', 1), ('CWE-405', 1), ('CWE-130', 1), ('CWE-194', 1), ('CWE-539', 1)]
221
{'CWE-20', 'CWE-79', 'CWE-863', 'CWE-352', 'CWE-476', 'CWE-434', 'CWE-78', 'CWE-269', 'CWE-416', 'CWE-287', 'CWE-125', 'CWE-22', 'CWE-120', 'CWE-89', 'CWE-787', 'NVD-CWE-Other'}
16
11232
16

<wv------------------------------------------------------------------------------------------->
year = '2021'
# year = '2022'
vec_len = 100
min_count = 1
window_len = 5
dense_unit = 128
wv_model_path  = '..//..//models//wv//'+year+"_"+str(vec_len)+"_"+str(min_count)+"_"+str(window_len)+'.pkl'
label_path = '..\\..\\data\\clean\\nvdcve-1.1-'+year+'_labels.csv'
n=30
cwe_count = 16  # 2021

self.c1 = Conv2D(filters=12, kernel_size=(3, vec_len), padding='same')  # 卷积层
        self.b1 = BatchNormalization()  # BN层
        self.a1 = Activation('relu')  # 激活层
        self.p1 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')  # 池化层
        self.d1 = Dropout(0.2)  # dropout层

        self.flatten = Flatten()
        self.f1 = Dense(dense_unit, activation='relu')
        self.d2 = Dropout(0.2)
        self.f2 = Dense(cwe_count, activation='softmax')


281/281 [==============================] - 3s 3ms/step - loss: 2.7964 - accuracy: 0.3192
Epoch 2/10
281/281 [==============================] - 1s 3ms/step - loss: 1.5473 - accuracy: 0.4827
Epoch 3/10
281/281 [==============================] - 1s 3ms/step - loss: 1.3371 - accuracy: 0.5442
Epoch 4/10
281/281 [==============================] - 1s 3ms/step - loss: 1.1942 - accuracy: 0.5863
Epoch 5/10
281/281 [==============================] - 1s 3ms/step - loss: 1.1445 - accuracy: 0.6065
Epoch 6/10
281/281 [==============================] - 1s 3ms/step - loss: 1.0835 - accuracy: 0.6182
Epoch 7/10
281/281 [==============================] - 1s 3ms/step - loss: 1.0281 - accuracy: 0.6312
Epoch 8/10
281/281 [==============================] - 1s 3ms/step - loss: 0.9580 - accuracy: 0.6632
Epoch 9/10
281/281 [==============================] - 1s 3ms/step - loss: 0.9261 - accuracy: 0.6715
Epoch 10/10
281/281 [==============================] - 1s 3ms/step - loss: 0.8815 - accuracy: 0.6795
71/71 [==============================] - 0s 2ms/step - loss: 0.8404 - accuracy: 0.7201
last score: [0.8404455780982971, 0.7200711965560913]
</wv------------------------------------------------------------------------------------------->

<tfi-wv---------------------------------------------------------------------------------------->
year = '2021'
vec_len = 100
min_count = 1
window_len = 5
ig_num = 1000
sentence_len = 30
n=sentence_len
dense_unit = 128
cwe_count = 16  # 2021

281/281 [==============================] - 3s 3ms/step - loss: 2.8728 - accuracy: 0.3030
Epoch 2/10
281/281 [==============================] - 1s 3ms/step - loss: 1.5595 - accuracy: 0.4792
Epoch 3/10
281/281 [==============================] - 1s 3ms/step - loss: 1.3509 - accuracy: 0.5351
Epoch 4/10
281/281 [==============================] - 1s 3ms/step - loss: 1.2717 - accuracy: 0.5545
Epoch 5/10
281/281 [==============================] - 1s 3ms/step - loss: 1.1907 - accuracy: 0.5864
Epoch 6/10
281/281 [==============================] - 1s 3ms/step - loss: 1.1016 - accuracy: 0.6106
Epoch 7/10
281/281 [==============================] - 1s 3ms/step - loss: 1.0774 - accuracy: 0.6074
Epoch 8/10
281/281 [==============================] - 1s 3ms/step - loss: 1.0557 - accuracy: 0.6227
Epoch 9/10
281/281 [==============================] - 1s 3ms/step - loss: 1.0376 - accuracy: 0.6259
Epoch 10/10
281/281 [==============================] - 1s 3ms/step - loss: 1.0048 - accuracy: 0.6460
71/71 [==============================] - 0s 2ms/step - loss: 0.9209 - accuracy: 0.7174
last score: [0.9209462404251099, 0.7174009680747986]
</tfi-wv----------------------------------------------------------------------------------------->

<fast------------------------------------------------------------------------------------------->
year = '2021'
vec_len = 100
min_count = 1
window_len = 5
dense_unit = 128
fast_model_path  = '..//..//models//fasttext//'+year+"_"+str(vec_len)+"_"+str(min_count)+"_"+str(window_len)+'.pkl'
label_path = '..\\..\\data\\clean\\nvdcve-1.1-'+year+'_labels.csv'
n=30
cwe_count = 16  # 2021

self.c1 = Conv2D(filters=12, kernel_size=(3, vec_len), padding='same')  # 卷积层
        self.b1 = BatchNormalization()  # BN层
        self.a1 = Activation('relu')  # 激活层
        self.p1 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')  # 池化层
        self.d1 = Dropout(0.2)  # dropout层

        self.flatten = Flatten()
        self.f1 = Dense(128, activation='relu')
        self.d2 = Dropout(0.2)
        self.f2 = Dense(cwe_count, activation='softmax')

281/281 [==============================] - 3s 3ms/step - loss: 3.4853 - accuracy: 0.2548
Epoch 2/10
281/281 [==============================] - 1s 3ms/step - loss: 1.7437 - accuracy: 0.4126
Epoch 3/10
281/281 [==============================] - 1s 3ms/step - loss: 1.5300 - accuracy: 0.4656
Epoch 4/10
281/281 [==============================] - 1s 3ms/step - loss: 1.4384 - accuracy: 0.4861
Epoch 5/10
281/281 [==============================] - 1s 3ms/step - loss: 1.3654 - accuracy: 0.5129
Epoch 6/10
281/281 [==============================] - 1s 3ms/step - loss: 1.3283 - accuracy: 0.5241
Epoch 7/10
281/281 [==============================] - 1s 3ms/step - loss: 1.2755 - accuracy: 0.5409
Epoch 8/10
281/281 [==============================] - 1s 3ms/step - loss: 1.2502 - accuracy: 0.5478
Epoch 9/10
281/281 [==============================] - 1s 3ms/step - loss: 1.1954 - accuracy: 0.5619
Epoch 10/10
281/281 [==============================] - 1s 3ms/step - loss: 1.1815 - accuracy: 0.5658
71/71 [==============================] - 0s 2ms/step - loss: 1.0349 - accuracy: 0.6782
last score: [1.0349352359771729, 0.6782376766204834]
</fast------------------------------------------------------------------------------------------->
